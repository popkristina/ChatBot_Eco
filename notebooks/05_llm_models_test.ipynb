{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398e49d9-d025-416e-bd5f-a1e337bc6794",
   "metadata": {},
   "source": [
    "### Notebook intended to test models from Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87e09b42-8887-44b3-a7d4-96e32d9a7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fastapi.responses import RedirectResponse\n",
    "from langserve import add_routes\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_cohere import CohereEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bcf812-5af4-4d8c-9593-d1c3df478791",
   "metadata": {},
   "source": [
    "#### Define LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "070cdaf5-bc4e-4ab0-9976-1b6c7fb8d680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm = ChatGroq(temperature=0, \n",
    "               model_name=\"mixtral-8x7b-32768\", \n",
    "               groq_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e1430a-6db0-476f-8a8a-42b7da58e816",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "Use the provided context to answer the user's question. If you don't know the answer, say you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dccf5d4-350b-4180-8145-d9ddc174fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = ChatPromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3761d8f3-f421-40b5-b7b8-5e86ecca8487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the provided context to answer the user's question. If you don't know the answer, say you don't know.\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aac46d1-1b9f-4e61-bf28-b8e612b44f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a7e04bd-5528-4d88-a67c-55c3a5c73e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a50f876a-f8ba-4530-a196-0dad094acf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Cohere API key:  ········\n"
     ]
    }
   ],
   "source": [
    "from langchain_cohere import CohereEmbeddings\n",
    "import getpass\n",
    "\n",
    "if not os.getenv(\"COHERE_API_KEY\"):\n",
    "    os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter your Cohere API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9365aae5-892d-4791-81f3-a29159e3172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = CohereEmbeddings(\n",
    "    model=\"embed-english-v3.0\",\n",
    ")\n",
    "\n",
    "faiss_index = FAISS.load_local(\"../langserve_index\", embeddings_model, allow_dangerous_deserialization=True)\n",
    "retriever = faiss_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45df6a9e-c860-418b-8cd1-ebbe6339b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point_chain = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d17829bc-0090-4cff-9506-5d93d1d02312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['FAISS', 'CohereEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000015C83CC0F40>, search_kwargs={}),\n",
       "  question: RunnablePassthrough()\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry_point_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "080ce248-2d11-4d9a-a3c8-5fbef70de4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a20ec9ec-2912-4baf-a9c8-425b6075ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = entry_point_chain | rag_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b8b9e8f-702c-4405-984c-9a1c957c39e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['FAISS', 'CohereEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000015C83CC0F40>, search_kwargs={}),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the provided context to answer the user's question. If you don't know the answer, say you don't know.\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\"), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000015C832D3B80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000015C832D4730>, temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb287d-023a-4bb9-b3a4-d46ef572b13b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
